Crear el directorio para la configuración del socket de Podman:

sudo mkdir -p /etc/systemd/system/podman.socket.d

Este comando crea la estructura de directorios para almacenar archivos de configuración relacionados con el socket de Podman.

==================================================================================================================================================================
Crear y configurar podman.conf:



# Crear el archivo
vi /etc/systemd/system/podman.socket.d/podman.conf

Agrega el siguiente contenido a podman.conf:


ini
[Socket]
ListenStream=
ListenStream=/var/run/docker.sock
SocketMode=770
SocketUser=elastic
SocketGroup=podman


Establece la propiedad y los permisos:

sudo chown root:root /etc/systemd/system/podman.socket.d/podman.conf
sudo chmod 0644 /etc/systemd/system/podman.socket.d/podman.conf

==================================================================================================================================================================
Crear el script docker:

vi /usr/bin/docker
Agrega el siguiente contenido a /usr/bin/docker:

#!/bin/bash
podman-remote --url unix:///var/run/docker.sock "$@"


Establece permisos:

sudo chmod 0755 /usr/bin/docker

==================================================================================================================================================================
Configurar storage.conf:

# Agrega estas líneas a la sección [storage] en el archivo /etc/containers/storage.conf
sudo nano /etc/containers/storage.conf
Agrega:

ini

runroot = "/mnt/data/docker/runroot/"
graphroot = "/mnt/data/docker"

==================================================================================================================================================================
Habilitar los servicios de Podman:


sudo systemctl enable podman.service
sudo systemctl enable podman-restart.service

==================================================================================================================================================================
Habilitar el módulo del kernel overlay:

echo "overlay" | sudo tee -a /etc/modules-load.d/overlay.conf

==================================================================================================================================================================
Formatear la partición de datos adicional:

sudo mkfs.xfs /dev/nvme1n1

==================================================================================================================================================================
Crear el directorio de punto de montaje:

sudo install -o elastic -g elastic -d -m 700 /mnt/data

==================================================================================================================================================================
Agregar entrada a /etc/fstab para el volumen XFS:


sudo nano /etc/fstab
Agrega la línea (ajusta /dev/nvme1n1 según sea necesario):

/dev/nvme1n1 /mnt/data xfs defaults,nofail,x-systemd.automount,prjquota,pquota 0 2

Luego reinicia:
sudo systemctl daemon-reload
sudo systemctl restart local-fs.target

==================================================================================================================================================================
Establecer permisos en el dispositivo montado:

ls /mnt/data
sudo chown elastic:elastic /mnt/data

==================================================================================================================================================================
Crear el directorio de almacenamiento del servicio Docker:

sudo install -o elastic -g elastic -d -m 700 /mnt/data/docker

==================================================================================================================================================================
Deshabilitar el servicio firewalld:

sudo systemctl disable firewalld

==================================================================================================================================================================
Configurar parámetros del kernel:

sudo nano /etc/sysctl.conf
Agrega el siguiente contenido:

ini

vm.max_map_count=262144
net.ipv4.ip_forward=1
net.ipv4.tcp_retries2=5
vm.swappiness=1


Aplica la nueva configuración:

sudo sysctl -p
sudo systemctl restart NetworkManager

==================================================================================================================================================================
Ajustar los límites del sistema:

sudo nano /etc/security/limits.conf
Agrega los valores de configuración especificados.

==================================================================================================================================================================
Opcional: Autenticar al usuario elastic para el registro de Docker:

nano /home/elastic/.docker/config.json
Agrega el token de autenticación para el registro de Docker.

==================================================================================================================================================================
Reiniciar el servicio de Podman:

sudo systemctl daemon-reload
sudo systemctl restart podman

==================================================================================================================================================================
Reiniciar el host de RHEL:

sudo reboot


Estos pasos configuran el entorno para ejecutar Elastic en una instancia de un solo nodo utilizando Podman. Asegúrate de seguir cuidadosamente cada paso y modifica las configuraciones según sea necesario para tu configuración específica.

________________________________________________________________________________________________________________________________________________________________
Podman-compose.yaml :

version: '3'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.x
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
    volumes:
      - /mnt/data/elasticsearch:/usr/share/elasticsearch/data
      - /etc/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
    ports:
      - "9200:9200"
      - "9300:9300"
    group: "podman"
    networks:
      - elastic

  kibana:
    image: docker.elastic.co/kibana/kibana:7.x
    container_name: kibana
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
    volumes:
      - /etc/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
    ports:
      - "5601:5601"
    group: "podman"
    networks:
      - elastic

  logstash:
    image: docker.elastic.co/logstash/logstash:7.x
    container_name: logstash
    volumes:
      - /etc/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - /etc/logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5044:5044"
    group: "podman"
    networks:
      - elastic

networks:
  elastic:
    driver: bridge


podman-compose up -d

Error: unable to start container "dddeed6a97dae54d1f5bbab0cfec279e6305874e29203e3eca7c9973ac03b648": unable to find user elastic: no matching entries in passwd file


[root@dkr-elk-hc01 ~]# podman-compose -f elastic-kibana-logstash_pcompose.yaml up -d
podman-compose version: 1.0.6
['podman', '--version', '']
using podman version: 4.6.1
** excluding:  set()
['podman', 'ps', '--filter', 'label=io.podman.compose.project=root', '-a', '--format', '{{ index .Labels "io.podman.compose.config-hash"}}']
recreating: ...
** excluding:  set()
podman stop -t 10 logstash
logstash
exit code: 0
podman stop -t 10 kibana
kibana
exit code: 0
podman stop -t 10 elasticsearch
elasticsearch
exit code: 0
podman rm logstash
logstash
exit code: 0
podman rm kibana
kibana
exit code: 0
podman rm elasticsearch
elasticsearch
exit code: 0
recreating: done


['podman', 'network', 'exists', 'root_elastic']
podman run --name=elasticsearch -d --label io.podman.compose.config-hash=828899f67f46aed630500b3880a3bc1f1794d1b8ac9a3ea9c7d281464e4bf67f --label io.podman.compose.project=root --label io.podman.compose.version=1.0.6 --label PODMAN_SYSTEMD_UNIT=podman-compose@root.service --label com.docker.compose.project=root --label com.docker.compose.project.working_dir=/root --label com.docker.compose.project.config_files=elastic-kibana-logstash_pcompose.yaml --label com.docker.compose.container-number=1 --label com.docker.compose.service=elasticsearch -e discovery.type=single-node -v /mnt/data/elasticsearch:/usr/share/elasticsearch/data -v /etc/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro --net root_elastic --network-alias elasticsearch -p 9200:9200 -p 9300:9300 registry.connect.redhat.com/elastic/elasticsearch:8.11.1-63f123cb
Error: OCI runtime error: crun: mount `/etc/elasticsearch/elasticsearch.yml` to `usr/share/elasticsearch/config/elasticsearch.yml`: Not a directory
exit code: 126
podman start elasticsearch
Error: OCI runtime error: unable to start container "73e3586bff6f35b58656dc0743a650460201357107b019ba1da11cb0f04bc0d0": crun: mount `/etc/elasticsearch/elasticsearch.yml` to `usr/share/elasticsearch/config/elasticsearch.yml`: Not a directory
exit code: 125
['podman', 'network', 'exists', 'root_elastic']
podman run --name=kibana -d --label io.podman.compose.config-hash=828899f67f46aed630500b3880a3bc1f1794d1b8ac9a3ea9c7d281464e4bf67f --label io.podman.compose.project=root --label io.podman.compose.version=1.0.6 --label PODMAN_SYSTEMD_UNIT=podman-compose@root.service --label com.docker.compose.project=root --label com.docker.compose.project.working_dir=/root --label com.docker.compose.project.config_files=elastic-kibana-logstash_pcompose.yaml --label com.docker.compose.container-number=1 --label com.docker.compose.service=kibana -e ELASTICSEARCH_URL=http://elasticsearch:9200 -v /etc/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:ro --net root_elastic --network-alias kibana -p 5601:5601 registry.connect.redhat.com/elastic/kibana:8.11.3-65c4b655
Error: OCI runtime error: crun: mount `/etc/kibana/kibana.yml` to `usr/share/kibana/config/kibana.yml`: Not a directory
exit code: 126
podman start kibana
Error: OCI runtime error: unable to start container "3a6c4f4b059e93cf8932e2d1344a7754dafdc40606daa29bc968d53048980f21": crun: mount `/etc/kibana/kibana.yml` to `usr/share/kibana/config/kibana.yml`: Not a directory
exit code: 125
['podman', 'network', 'exists', 'root_elastic']
podman run --name=logstash -d --label io.podman.compose.config-hash=828899f67f46aed630500b3880a3bc1f1794d1b8ac9a3ea9c7d281464e4bf67f --label io.podman.compose.project=root --label io.podman.compose.version=1.0.6 --label PODMAN_SYSTEMD_UNIT=podman-compose@root.service --label com.docker.compose.project=root --label com.docker.compose.project.working_dir=/root --label com.docker.compose.project.config_files=elastic-kibana-logstash_pcompose.yaml --label com.docker.compose.container-number=1 --label com.docker.compose.service=logstash -v /etc/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml:ro -v /etc/logstash/pipeline:/usr/share/logstash/pipeline:ro --net root_elastic --network-alias logstash -p 5044:5044 registry.connect.redhat.com/elastic/logstash:8.11.3-65c4b655
Error: OCI runtime error: crun: mount `/etc/logstash/logstash.yml` to `usr/share/logstash/config/logstash.yml`: Not a directory
exit code: 126
podman start logstash
Error: OCI runtime error: unable to start container "aefc09f52a69ade7d9b7c06961b09a7ed696f17bda451cd4b9cabcb9ca033068": crun: mount `/etc/logstash/logstash.yml` to `usr/share/logstash/config/logstash.yml`: Not a directory
exit code: 125





==================================================================================================================================================================================================================
Before creating the container from the downloaded image, we need to create the data directory with the required ownership and SELinux context.


# mkdir /dbdata
# chown -R 27:27 /dbdata/
# semanage fcontext -a -t container_file_t '/dbdata(./*)?'
# restorecon -RFv /dbdata/
[root@openshift-lab ~]# semanage fcontext -a -t container_file_t '/dbdata(./*)?'
[root@openshift-lab ~]# restorecon -RFv /dbdata/
Relabeled /dbdata from unconfined_u:object_r:default_t:s0 to system_u:object_r:container_file_t:s0
[root@openshift-lab ~]# 
Once the volume is ready, create the container.

.



[root@dkr-elk-hc01 ~]# podman-compose -f elastic-kibana-logstash_pcompose.yaml up
podman-compose version: 1.0.6
['podman', '--version', '']
using podman version: 4.6.1
** excluding:  set()
['podman', 'ps', '--filter', 'label=io.podman.compose.project=root', '-a', '--format', '{{ index .Labels "io.podman.compose.config-hash"}}']
['podman', 'network', 'exists', 'root_elastic']
['podman', 'network', 'create', '--label', 'io.podman.compose.project=root', '--label', 'com.docker.compose.project=root', '--driver', 'bridge', 'root_elastic']
['podman', 'network', 'exists', 'root_elastic']
podman create --name=elasticsearch --label io.podman.compose.config-hash=87fa772da6e0b601421a410e45eec59fbc3d48a2e81d5c304302ad9386018591 --label io.podman.compose.project=root --label io.podman.compose.version=1.0.6 --label PODMAN_SYSTEMD_UNIT=podman-compose@root.service --label com.docker.compose.project=root --label com.docker.compose.project.working_dir=/root --label com.docker.compose.project.config_files=elastic-kibana-logstash_pcompose.yaml --label com.docker.compose.container-number=1 --label com.docker.compose.service=elasticsearch -e discovery.type=single-node -v /elasticsearch/single-node/data:/usr/share/elasticsearch/data -v /etc/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml --net root_elastic --network-alias elasticsearch -p 9200:9200 -p 9300:9300 registry.connect.redhat.com/elastic/elasticsearch:8.11.1-63f123cb
Trying to pull registry.connect.redhat.com/elastic/elasticsearch:8.11.1-63f123cb...
Getting image source signatures
Copying blob bf3fa768b9bf done
Copying blob d88ca31211cc done
Copying blob 5f92df8b6dc4 done
Copying blob 83f532a47f85 done
Copying blob 80afe8e53846 done
Copying blob 89732bc75041 done
Copying blob b5d62cb7a76e done
Copying blob a6b2e70ab83b done
Copying blob e385ae252727 done
Copying blob 086bac5f98a4 done
Copying config 43d79a01ee done
Writing manifest to image destination
29b7466817bf0d75e3ae2d1a7249f32e27321977ca0401124f706648ef42bfcc
exit code: 0
['podman', 'network', 'exists', 'root_elastic']
podman create --name=kibana --label io.podman.compose.config-hash=87fa772da6e0b601421a410e45eec59fbc3d48a2e81d5c304302ad9386018591 --label io.podman.compose.project=root --label io.podman.compose.version=1.0.6 --label PODMAN_SYSTEMD_UNIT=podman-compose@root.service --label com.docker.compose.project=root --label com.docker.compose.project.working_dir=/root --label com.docker.compose.project.config_files=elastic-kibana-logstash_pcompose.yaml --label com.docker.compose.container-number=1 --label com.docker.compose.service=kibana -e ELASTICSEARCH_URL=http://elasticsearch:9200 -v /etc/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:ro --net root_elastic --network-alias kibana -p 5601:5601 registry.connect.redhat.com/elastic/kibana:8.11.3-65c4b655
Trying to pull registry.connect.redhat.com/elastic/kibana:8.11.3-65c4b655...
Getting image source signatures
Copying blob 550c6d361d0e done
Copying blob 88cd120f5709 done
Copying blob 89732bc75041 skipped: already exists
Copying blob 159b78b51f1c done
Copying blob 009e43b06aa4 done
Copying blob 86173ca81688 done
Copying blob 1dbaac751c57 done
Copying blob ba94b0241a73 done
Copying blob 89732bc75041 skipped: already exists
Copying blob 81735a894803 done
Copying blob 5801a176c82c done
Copying blob 77e70835f219 done
Copying blob 8af13b3e5ea0 done
Copying blob cfbb83384d4b done
Copying blob 673cd977a8e1 done
Copying blob 7edd5e140771 done
Copying config 580cde05cb done
Writing manifest to image destination
3479f7d7daed2c0a903fcd3c90571297f6f34dc3f9ff3afe34bb8b507eb9eb63
exit code: 0
podman start -a elasticsearch
podman start -a kibana
Exception in thread "main" java.nio.file.AccessDeniedException: /usr/share/elasticsearch/data
        at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90)
        at java.base/sun.nio.fs.UnixException.asIOException(UnixException.java:115)
        at java.base/sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:477)
        at java.base/java.nio.file.Files.newDirectoryStream(Files.java:481)
        at java.base/java.nio.file.Files.list(Files.java:3772)
        at org.elasticsearch.xpack.security.cli.AutoConfigureNode.isDirEmpty(AutoConfigureNode.java:1146)
        at org.elasticsearch.xpack.security.cli.AutoConfigureNode.execute(AutoConfigureNode.java:166)
        at org.elasticsearch.server.cli.ServerCli.autoConfigureSecurity(ServerCli.java:165)
        at org.elasticsearch.server.cli.ServerCli.execute(ServerCli.java:86)
        at org.elasticsearch.common.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:54)
        at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:85)
        at org.elasticsearch.cli.Command.main(Command.java:50)
        at org.elasticsearch.launcher.CliToolLauncher.main(CliToolLauncher.java:64)
[kibana]        | Kibana is currently running with legacy OpenSSL providers enabled! For details and instructions on how to disable see https://www.elastic.co/guide/en/kibana/8.11/production.html#openssl-legacy-provider
exit code: 1
[kibana]        | {"log.level":"info","@timestamp":"2024-01-10T23:44:47.758Z","log":{"logger":"elastic-apm-node"},"agentVersion":"4.1.0","env":{"pid":2,"proctitle":"/usr/share/kibana/bin/../node/bin/node","os":"linux 5.14.0-362.13.1.el9_3.x86_64","arch":"x64","host":"3479f7d7daed","timezone":"UTC+00","runtime":"Node.js v18.18.2"},"config":{"serviceName":{"source":"start","value":"kibana","commonName":"service_name"},"serviceVersion":{"source":"start","value":"8.11.3","commonName":"service_version"},"serverUrl":{"source":"start","value":"https://kibana-cloud-apm.apm.us-east-1.aws.found.io/","commonName":"server_url"},"logLevel":{"source":"default","value":"info","commonName":"log_level"},"active":{"source":"start","value":true},"contextPropagationOnly":{"source":"start","value":true},"environment":{"source":"start","value":"production"},"globalLabels":{"source":"start","value":[["git_rev","cc11667953f4734af414e8d8977b8d9dda5698ef"]],"sourceValue":{"git_rev":"cc11667953f4734af414e8d8977b8d9dda5698ef"}},"secretToken":{"source":"start","value":"[REDACTED]","commonName":"secret_token"},"breakdownMetrics":{"source":"start","value":false},"captureSpanStackTraces":{"source":"start","sourceValue":false},"centralConfig":{"source":"start","value":false},"metricsInterval":{"source":"start","value":120,"sourceValue":"120s"},"propagateTracestate":{"source":"start","value":true},"transactionSampleRate":{"source":"start","value":0.1,"commonName":"transaction_sample_rate"},"captureBody":{"source":"start","value":"off","commonName":"capture_body"},"captureHeaders":{"source":"start","value":false}},"activationMethod":"require","ecs":{"version":"1.6.0"},"message":"Elastic APM Node.js Agent v4.1.0"}
[kibana]        | [2024-01-10T23:44:49.567+00:00][INFO ][root] Kibana is starting
[kibana]        | [2024-01-10T23:44:49.648+00:00][INFO ][root] Kibana is shutting down
[kibana]        | [2024-01-10T23:44:49.654+00:00][FATAL][root] Reason: [config validation of [server].host]: value must be a valid hostname (see RFC 1123).
[kibana]        | Error: [config validation of [server].host]: value must be a valid hostname (see RFC 1123).
[kibana]        |     at ObjectType.validate (/usr/share/kibana/node_modules/@kbn/config-schema/src/types/type.js:94:13)
[kibana]        |     at ConfigService.validateAtPath (/usr/share/kibana/node_modules/@kbn/config/src/config_service.js:252:19)
[kibana]        |     at /usr/share/kibana/node_modules/@kbn/config/src/config_service.js:262:204
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/operators/map.js:10:37
[kibana]        |     at OperatorSubscriber._this._next (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/operators/OperatorSubscriber.js:33:21)
[kibana]        |     at OperatorSubscriber.Subscriber.next (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Subscriber.js:51:18)
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/operators/distinctUntilChanged.js:18:28
[kibana]        |     at OperatorSubscriber._this._next (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/operators/OperatorSubscriber.js:33:21)
[kibana]        |     at OperatorSubscriber.Subscriber.next (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Subscriber.js:51:18)
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/operators/map.js:10:24
[kibana]        |     at OperatorSubscriber._this._next (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/operators/OperatorSubscriber.js:33:21)
[kibana]        |     at OperatorSubscriber.Subscriber.next (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Subscriber.js:51:18)
[kibana]        |     at ReplaySubject._subscribe (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/ReplaySubject.js:54:24)
[kibana]        |     at ReplaySubject.Observable._trySubscribe (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Observable.js:41:25)
[kibana]        |     at ReplaySubject.Subject._trySubscribe (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Subject.js:123:47)
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Observable.js:35:31
[kibana]        |     at Object.errorContext (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/util/errorContext.js:22:9)
[kibana]        |     at ReplaySubject.Observable.subscribe (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Observable.js:26:24)
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/operators/share.js:66:18
[kibana]        |     at OperatorSubscriber.<anonymous> (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/util/lift.js:14:28)
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Observable.js:30:30
[kibana]        |     at Object.errorContext (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/util/errorContext.js:22:9)
[kibana]        |     at Observable.subscribe (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Observable.js:26:24)
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/operators/map.js:9:16
[kibana]        |     at OperatorSubscriber.<anonymous> (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/util/lift.js:14:28)
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Observable.js:30:30
[kibana]        |     at Object.errorContext (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/util/errorContext.js:22:9)
[kibana]        |     at Observable.subscribe (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Observable.js:26:24)
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/operators/distinctUntilChanged.js:13:16
[kibana]        |     at OperatorSubscriber.<anonymous> (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/util/lift.js:14:28)
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Observable.js:30:30
[kibana]        |     at Object.errorContext (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/util/errorContext.js:22:9)
[kibana]        |     at Observable.subscribe (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Observable.js:26:24)
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/operators/map.js:9:16
[kibana]        |     at SafeSubscriber.<anonymous> (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/util/lift.js:14:28)
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Observable.js:30:30
[kibana]        |     at Object.errorContext (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/util/errorContext.js:22:9)
[kibana]        |     at Observable.subscribe (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/Observable.js:26:24)
[kibana]        |     at /usr/share/kibana/node_modules/rxjs/dist/cjs/internal/firstValueFrom.js:24:16
[kibana]        |     at new Promise (<anonymous>)
[kibana]        |     at firstValueFrom (/usr/share/kibana/node_modules/rxjs/dist/cjs/internal/firstValueFrom.js:8:12)
[kibana]        |     at EnvironmentService.preboot (/usr/share/kibana/node_modules/@kbn/core-environment-server-internal/src/environment_service.js:50:169)
[kibana]        |     at Server.preboot (/usr/share/kibana/node_modules/@kbn/core-root-server-internal/src/server.js:146:55)
[kibana]        |     at Root.preboot (/usr/share/kibana/node_modules/@kbn/core-root-server-internal/src/root/index.js:47:32)
[kibana]        |     at processTicksAndRejections (node:internal/process/task_queues:95:5)
[kibana]        |     at bootstrap (/usr/share/kibana/node_modules/@kbn/core-root-server-internal/src/bootstrap.js:97:9)
[kibana]        |     at Command.<anonymous> (/usr/share/kibana/src/cli/serve/serve.js:211:5)

 FATAL  Error: [config validation of [server].host]: value must be a valid hostname (see RFC 1123).

exit code: 1


# Habilitar el servicio para el puerto 9200 (Elasticsearch)
firewall-cmd --permanent --add-service=9200/tcp --zone=public --add-interface=elastic --permanent
firewall-cmd --permanent --add-service=9200/tcp --zone=trusted --add-interface=elastic --permanent

# Habilitar el servicio para el puerto 9300 (Elasticsearch)
firewall-cmd --permanent --add-service=9300/tcp --zone=public --add-interface=elastic --permanent
firewall-cmd --permanent --add-service=9300/tcp --zone=trusted --add-interface=elastic --permanent

# Habilitar el servicio para el puerto 5601 (Kibana)
firewall-cmd --permanent --add-service=5601/tcp --zone=public --add-interface=elastic --permanent
firewall-cmd --permanent --add-service=5601/tcp --zone=trusted --add-interface=elastic --permanent

# Habilitar el servicio para el puerto 5044 (Logstash)
firewall-cmd --permanent --add-service=5044/tcp --zone=public --add-interface=elastic --permanent
firewall-cmd --permanent --add-service=5044/tcp --zone=trusted --add-interface=elastic --permanent

firewall-cmd --reload
systemctl status firewalld

elasticsearch.yml
------------------
cluster.name: single_node_podman
node.name: elasticsearch
path.data: /usr/share/elasticsearch/data
path.logs: /usr/share/elasticsearch/data
network.host: 0.0.0.0
discovery.type: single-node
xpack.license.self_generated.type: basic
#xpack.license.self_generated.type: trial
xpack.monitoring.collection.enabled: true
xpack.security.autoconfiguration.enabled: true
xpack.security.enabled: true
xpack.security.authc.api_key.enabled: true
xpack.security.enrollment.enabled: true
# Configuracion nativa - requiere persistencia y se administra a traves de kibana
#xpack.security.authc.realms.native.native1.type: native
#xpack.security.authc.realms.native.native1.order: 0
#xpack.security.authc.realms.native.native1.users.elastic: "elastic:podman_elastic:superuser"

# configuracion SSL | Certificados
#xpack.security.http.ssl.enabled: true
#xpack.security.http.ssl.keystore.path: /usr/share/elasticsearch/config/elastic-certificates.p12
#xpack.security.http.ssl.truststore.path: /usr/share/elasticsearch/config/elastic-certificates.p12
#xpack.security.transport.ssl.enabled: false
#xpack.security.transport.ssl.verification_mode: certificate



kibana.yml
------------
server.name: kibana
#server.host: "0"
elasticsearch.hosts: ["http://elasticsearch:9200"]
elasticsearch.auth.type: "basic"
elasticsearch.auth.basic.enabled: true
elasticsearch.username: "kibana"
elasticsearch.password: "podman_elastic"






[kibana] | [2024-01-12T23:50:30.807+00:00][FATAL][root] Reason: [config validation of [elasticsearch].username]: value of "elastic" is forbidden. This is a superuser account that cannot write to system indices that Kibana needs to function. Use a service account token instead. Learn more: https://www.elastic.co/guide/en/elasticsearch/reference/8.0/service-accounts.html
[kibana] | Error: [config validation of [elasticsearch].username]: value of "elastic" is forbidden. This is a superuser account that cannot write to system indices that Kibana needs to function. Use a service account token instead. Learn more: https://www.elastic.co/guide/en/elasticsearch/reference/8.0/service-accounts.html
[kibana] |     at ensureValidConfiguration (/usr/share/kibana/node_modules/@kbn/core-config-server-internal/src/ensure_valid_configuration.js:23:11)
[kibana] |     at Server.preboot (/usr/share/kibana/node_modules/@kbn/core-root-server-internal/src/server.js:162:5)
[kibana] |     at Root.preboot (/usr/share/kibana/node_modules/@kbn/core-root-server-internal/src/root/index.js:47:14)
[kibana] |     at bootstrap (/usr/share/kibana/node_modules/@kbn/core-root-server-internal/src/bootstrap.js:97:9)
[kibana] |     at Command.<anonymous> (/usr/share/kibana/src/cli/serve/serve.js:211:5)

 FATAL  Error: [config validation of [elasticsearch].username]: value of "elastic" is forbidden. This is a superuser account that cannot write to system indices that Kibana needs to function. Use a service account token instead. Learn more: https://www.elastic.co/guide/en/elasticsearch/reference/8.0/service-accounts.html

exit code: 78


[root@dkr-elk-hc01 ~]# podman exec -it elasticsearch /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana
WARNING: Owner of file [/usr/share/elasticsearch/config/users] used to be [root], but now is [elasticsearch]
WARNING: Owner of file [/usr/share/elasticsearch/config/users_roles] used to be [root], but now is [elasticsearch]
Unable to create enrollment token for scope [kibana]

ERROR: Unable to create an enrollment token. Elasticsearch node HTTP layer SSL configuration is not configured with a keystore, with exit code 73


          bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
          unzip config/certs/certs.zip -d config/certs;




mcKkdwV7fsdkgwx3ytv86pbZPeFHupx
fi

# Use the ENCRYPTION_KEY variable as needed
echo "XPACK_SECURITY_ENCRYPTIONKEY=${ENCRYPTION_KEY}"
echo "XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${ENCRYPTION_KEY}"
echo "XPACK_REPORTING_ENCRYPTIONKEY=${ENCRYPTION_KEY}"
